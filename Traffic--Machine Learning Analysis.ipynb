{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis Report\n",
    "\n",
    "I began by importing the cleaned dataset called \"traffic_clean\" and viewing its first 5 rows. \n",
    "\n",
    "Note:  Relevant portions from this report are interspersed throughout the code below for context.\n",
    "\n",
    "## Final Preparations of the Dataset\n",
    "\n",
    "I then filtered the dataset to include information pertaining only to drivers, rather than passengers or pedestrians, by setting the variable Person Type ('PER_TYP') equal to 1, Driver of a Motor Vehicle In-Transport. I then dropped a number of variables that, upon further examination, proved to contain duplicative information, such as 'WEATHER1', 'WEATHER2', 'CF1', 'CF2' and 'CF3' (containing causation information included in other variables) in an effort to simplify the model and reduce the chances of overfitting.  I also dropped irrelevant index variables that were used to initially create the dataset from separate datasets during the data wrangling phase, such as 'ST_CASE', 'VEH_NO' and 'PER_NO'. \n",
    "\n",
    "Most of the other variables were categorical in nature, and therefore had to be converted into binary variables in order to be used by the model in Sci-Kit Learn (hereinafter, \"sklearn\").  Some of these I converted by hand where the variable could be easily summarized by two classes (Rural(1) or Urban(0) or Traffic Control Device functioning or not (VTCONT_F = 1 or 0), for example. Other variables contained details that I surmised could have been useful to the model, such as WEATHER and road surface conditions ('VSURCOND'), so I created a dictionary of keys and values based on the numerical codes and corresponding definitions for these variables found in NHTSA's Fatality Analysis Reporting System Analytical User’s Manual, August 2016.  I then looped through this dictionary, converting the numerical codes into strings of the definitions provided. The variables were then in the proper state to be converted into binary variables later.  \n",
    "\n",
    "Three of the variables were purely numerical variables, Travel Speed ('TRAV_SP'), the driver's age ('AGE') and the number of drunk drivers involved in the accident ('DRUNK_DR'). Since nearly all of the other variables in the model were going to be binary categorical variables, I determined that the three numeric variables needed to be standardized in order to place them on roughly the same footing as the binaries so as not to unduly skew the data.  Accordingly, I divided each variable by twice their standard deviations.  *See also*, [here](http://andrewgelman.com/2009/07/11/when_to_standar/), providing additional justification for the aforementioned procedure.   \n",
    "\n",
    "I then converted the variables with descriptions obtained from the NHTSA manual to binaries using pandas' get_dummies function, resulting in the creation of several new binary columns.  The original, non-binary columns were then dropped. At this point, the dataframe contained 77 columns and was ready for the application of machine learning algorithms.  \n",
    "\n",
    "## Model Selection\n",
    "\n",
    "After preparing the dataset, called \"traffic_clean_ml\", I first split the dataset into an input dataframe and a target series, dropping the target variable 'SERIOUS_FATALS' from the prepared dataset to create an input dataframe X and created a second single column Series y consisting only of the target variable.  \n",
    "\n",
    "I next used sklearn's train_test_split function to split both X and y into train and test variables X_train, X_test, y_train and y_test such that 80% of the total dataset would be used for training the model, while 20% was withheld as unseen data for application of the model after training.  \n",
    "\n",
    "However, the ratio of 0's to 1's in the target variable is more than 10:1.  Prediction would be very difficult for most models under these circumstances.  Therefore I utilized oversampling in order to balance out the dataset, specifically, the RandomOverSampler function from the imblearn package.  The results are shown below, first showing the original imbalanced count of the target variable's classes followed by the counts of the rebalanced data after oversampling.  \n",
    "\n",
    "Given the categorical nature of the input and target variables, classification models appeared to be most appropriate here.  I assessed several classification models to determine which provided the strongest predictions:  logistic regression, an ensemble voting classifier and a k-nearest neighbors classifier.  \n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "To better prepare the dataset for logistic regression, I used a feature selection algorithm, recursive feature elimination (RFE) from sklearn, in order to narrow the data down to the most useful features.  RFE selected 18 features out of the total 76 which are shown below along with their rankings, with 1 being the strongest. The input dataframe X was then filtered for these features and the train_test_split and oversampling functions were then reapplied as before.  \n",
    "\n",
    "I next performed a grid search over the C hyperparameter using GridsearchCV using a fairly wide grid from -5 to 10 in logspace. After some time, the grid search settled on a C-value of 15264.18. However, the accuracy score of this logistic regression model on the training set was a somewhat disappointing 59.96 percent. \n",
    "\n",
    "I then ran the logistic regression model over the test set and obtained an accuracy score of 59.20%, very close to the accuracy score on the training set.  Thus, although the score was not impressive, there did not appear to be any overfitting here.  The Precision for the positive class (1) was .58, while the Recall (or Sensitivity) was .67.  Therefore, in 58% of cases the model correctly identified a serious fatality out of each time it predicted a serious fatality (where Precision is defined as the True Positives divided by the sum of True Positives and False Positives, $\\frac{TP}{(TP + FP)}$, where TP is True Positive and FP is False Positive). In 67% of instances it correctly identified a serious fatality out of all possible serious fatalities in the dataset (where Recall/Sensitivity is defined as True Positives divided by the sum of True Positives and False Negatives, $\\frac{TP}{(TP + FN)}$, where TP is True Positive and FN is False Negative).  The F1 score, the harmonic mean of the Precision and the Recall ($\\frac{2PR}{(P + R)}$, where P is Precision and R is Recall), was .62.  Given that the F1 score runs from 0 to 1.0, with 1.0 indicating the strongest model, this was a better than average score, though a bit mediocre.  The confusion matrix and classification report displaying the foregoing results are printed below.   \n",
    "\n",
    "I then plotted the ROC Curve for the model, which plots the False Positive Rate vs. the True Positive Rate and compares the curve derived to a reference line with a slope of 1, indicating results that could be obtained by pure chance(equal numbers of False Positives and True Positives).  The greater the area under the curve (AUC), the more True Positives and the stronger the model. The results for the logistic regression model are shown below, showing an area of just .59 and a curve just slightly above the reference line, thus indicating a model that performs just slighly better than chance.  I therefore resolved to experiment with other classification models in an effort to obtain better results.  \n",
    "\n",
    "### Voting Classifier and Model Comparison\n",
    "\n",
    "I next used an ensemble Voting Classifier model that contained a logistic regression classifer, a Random Forest classifier and a K-Nearest Neighbors classifer.  After training the ensemble on the training set, I obtained an accuracy score of approximately 98.5%.  Running a loop over each component model in addition to the Voting Classifier, I obtained the following accuracy scores for the test data to the nearest tenth of a percent:  Logistic Regression at 58.9% (not using feature reduction or hyperparameter selection here), Random Forest at 61.0%, K-Nearest Neighbors at 75.8% and the Voting Classifier at 70.7%.  \n",
    "\n",
    "I attempted to improve the results from the Random Forest and Voting Classifier and in both cases still got inferior results compared to K-Neighbors.  \n",
    "\n",
    "For Random forest, I increased the number of trees to 300.  The improvement to the accuracy score was about .5 percent.  I ran small loop from 10, the default value, to 30 similar to what I did for knn to get an optimum number of estimators, just to see if there was any improvement as the number of estimators was increased and there was virtually none, as shown in the bottom cell.  \n",
    "\n",
    "I then attempted to use 300 estimators directly in the Voting Classifier.  The accuracy score was 0.6162, only a slight improvement, and appears to be supported by the plot below.  \n",
    "\n",
    "I also attempted to adjust the weights for the Voting Classifier to get an improved score.  I adjusted the weights to [.1, .2, .7], where .1 was for the logistic regression, .2 was for the Random Forest and .7 was for KNeighbors.  The Voting Classifier had an improved score of .7575, just slightly less than the KNeighbors classifier at .7577.  \n",
    "\n",
    "I also looked at the Precision, Recall and F1 scores for both methods.  For the Random Forest (with n_estimators=300), the Precision for the positive class was a very high .98, but the Recall was only a .24.  The F1 score for the positive class was only a .38, so this simply does not appear to be a good model for this dataset.  For the Voting Classifier, the Precision for the positive class was a .85, but only a .63 for the Recall and a .72 for the F1 score.  The F1 score here on the positive class, while decent, is still .01 less than the F1 score for the positive class using KNeighbors.  Random Forest and Voting Classifier appear to be making few Type I errors, but a large number of Type II errors. \n",
    "\n",
    "Since the K-Nearest Neighbors model performed the best, I ultimately chose to use this model for the present dataset.  \n",
    "\n",
    "### K-Nearest Neighbors Classifier\n",
    "\n",
    "In order to obtain the optimal k to use for the K-Nearest Neighbors classifier, I looped over several possible k-values from 1 through 8 and plotted the accuracy scores for both the training set and test set in a single plot.  This plot may be viewed in the bottom cell.  (Please note that it takes a substantial amount of time to run, i.e., approximately 20 minutes, and for this reason has been set off from the other cells in this notebook.)  \n",
    "\n",
    "Although k=3 and k=4 gave the highest accuracy scores, there was still a substantial amount of overfitting here.  K-Neighbors overfits more at k=4 by 21.7 percentage points vs. k=7 with 17.4 percentage points overfitting.  The drop in test accuracy is a little under 2 percent going from k=4 (75.8%) to k=7 at 74.2%, so the small drop in accuracy of 1.6% appears to be  worth the 4.3% drop in overfitting. I also attempted to use a weighting function for the nearest neighbors such that weights would be inversely proportional to distance using the weights='distance' parameter.  However, this also resulted in overfitting, and the improvements it provided were again minimal, as illustrated further in the second to last plot below. Accordingly, I ultimately adopted k=7 as the k-value for this model with the weights equal to 1. \n",
    "\n",
    "At k=7, the training accuracy score for the K-Nearest Neighbors classifier was 91.6%, while the testing accuracy score was, as stated, 74.2%. The Precision for the positive class (1) was .76, while the Recall (or Sensitivity) was .71.  Therefore, in 76% of cases the model correctly identified a serious fatality out of each time it predicted a serious fatality. In 71% of instances it correctly identified a serious fatality out of all possible serious fatalities in the dataset.  Finally, the F1 score for the positive class was .73. All of these scores thus indicated a substantial improvement over the previous logistic regression model. The confusion matrix and classification report displaying the foregoing results are printed below.\n",
    "\n",
    "I then plotted the ROC Curve for the present model. The results for the K-Nearest Neighbors model are shown below, showing an area under the curve (AUC) of .74 and a curve that is substantially above the 45 degree reference line, thus indicating a model that performs much better than chance.  \n",
    "\n",
    "## Analysis and Conclusion\n",
    "\n",
    "Despite the improved scores obtained through the K-Nearest Neighbors model on the test data, there was still overfitting unlike with the logistic regression model where feature reduction algorithms were employed.  \n",
    "\n",
    "The use of PCA and other feature-reducing tools was attempted with the K-Nearest Neighbors model, but ultimately had no beneficial impact since the nature of the data was such that each feature had to be split into many sub-features first that then needed to be binarized before being able to submit the data to a machine learning algorithm. Removing subfeatures using a feature reducer resulted in some subfeatures of a given feature being lost, but not all.  This resulted in substantially reduced accuracy when using feature reducers. Nevertheless, I was able to remove some features by hand at the outset before binarizing the variables where I observed redundancy between features. \n",
    "\n",
    "Despite attempting to use an ensemble Voting Classifier method consisting of Logistic Regression, a Random Forest and K-Nearest Neighbors, it failed to outperform K-Nearest Neighbors, as did the Random Forest by itself. Perhaps the Voting Classifier was not performing better than its components because these methods all have similar strengths and weaknesses (at least with respect to the present dataset), so we don’t have a situation where the strengths of one component make up for the weaknesses in another.  Instead there was just an averaging of results, such that the Voting Classifier would never perform better than its strongest component. The issue is likely related to the dataset itself and the way that the variables had to be subdivided into binaries, thus making it too rigid. K-Neighbors likely worked better here because, as noted by the Sci-Kit Learn User Guide, \"it does not attempt to construct a general internal model, but simply stores instances of the training data\" and \"...is often successful in classification situations where the decision boundary is very irregular\", as is likely the situation here. Based on the foregoing, the K-Nearest Neighbors method appears to be superior with respect to the present dataset. \n",
    "\n",
    "As discussed above, I was ultimately able to reduce the extent of overfitting by selecting a higher k-value at k=7, rather than at k=4, and this appeared to provide the best trade-off between reducing overfitting and maximizing accuracy.  In addition to an improved accuracy score, the model also provided improved Precision, Recall and F1 scores and a much greater area under the curve in the model's ROC plot. Therefore, this model appears to have maximized its predictive power and successfully predicted the occurrence of serious fatalities at a high rate with the given data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Excerpts\n",
    "\n",
    "I began by importing the cleaned dataset called \"traffic_clean\" and viewing its first 5 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>RUR_URB</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>RELJCT1</th>\n",
       "      <th>RELJCT2</th>\n",
       "      <th>WRK_ZONE</th>\n",
       "      <th>...</th>\n",
       "      <th>BIN_SPEEDREL</th>\n",
       "      <th>BIN_REST_USE</th>\n",
       "      <th>BIN_DRUGS</th>\n",
       "      <th>BIN_P_SF1</th>\n",
       "      <th>BIN_MDRDSTRD</th>\n",
       "      <th>BIN_DRIMPAIR</th>\n",
       "      <th>BIN_MFACTOR</th>\n",
       "      <th>BIN_MDRMANAV</th>\n",
       "      <th>BIN_MVISOBSC</th>\n",
       "      <th>SERIOUS_FATALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST_CASE  MONTH  YEAR  DAY_WEEK  HOUR  RUR_URB  ROUTE  RELJCT1  RELJCT2  \\\n",
       "0    10001      1  2015         5     2        1      3        0        1   \n",
       "1    10002      1  2015         5    22        1      1        0        1   \n",
       "2    10003      1  2015         5     1        1      2        0        1   \n",
       "3    10003      1  2015         5     1        1      2        0        1   \n",
       "4    10004      1  2015         1     0        1      3        0        1   \n",
       "\n",
       "   WRK_ZONE       ...        BIN_SPEEDREL  BIN_REST_USE  BIN_DRUGS  BIN_P_SF1  \\\n",
       "0         0       ...                   0             0          0          0   \n",
       "1         0       ...                   1             0          0          0   \n",
       "2         0       ...                   0             0          0          0   \n",
       "3         0       ...                   0             0          0          0   \n",
       "4         0       ...                   0             0          0          0   \n",
       "\n",
       "   BIN_MDRDSTRD  BIN_DRIMPAIR  BIN_MFACTOR  BIN_MDRMANAV  BIN_MVISOBSC  \\\n",
       "0             0             0            0             0             0   \n",
       "1             0             0            0             0             0   \n",
       "2             0             1            0             0             0   \n",
       "3             0             1            0             0             0   \n",
       "4             0             1            0             0             0   \n",
       "\n",
       "   SERIOUS_FATALS  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Read cleaned csv to new dataframe\n",
    "traffic_clean = pd.read_csv(\"traffic_clean.csv\")\n",
    "traffic_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MONTH', 'DAY_WEEK', 'HOUR', 'RUR_URB', 'ROUTE', 'RELJCT2', 'WRK_ZONE',\n",
      "       'LGT_COND', 'WEATHER', 'DRUNK_DR', 'HAZ_INV', 'TRAV_SP', 'SPEEDREL',\n",
      "       'VSPD_LIM', 'VPROFILE', 'VPAVETYP', 'VSURCOND', 'VTRAFCON', 'VTCONT_F',\n",
      "       'AGE', 'REST_USE', 'DRUGS', 'MDRDSTRD', 'DRIMPAIR', 'MFACTOR',\n",
      "       'MDRMANAV', 'MVISOBSC', 'BIN_WRK_ZONE', 'BIN_SPEEDREL', 'BIN_REST_USE',\n",
      "       'BIN_DRUGS', 'BIN_MDRDSTRD', 'BIN_DRIMPAIR', 'BIN_MFACTOR',\n",
      "       'BIN_MDRMANAV', 'BIN_MVISOBSC', 'SERIOUS_FATALS'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>RUR_URB</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>RELJCT2</th>\n",
       "      <th>WRK_ZONE</th>\n",
       "      <th>LGT_COND</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>DRUNK_DR</th>\n",
       "      <th>...</th>\n",
       "      <th>BIN_WRK_ZONE</th>\n",
       "      <th>BIN_SPEEDREL</th>\n",
       "      <th>BIN_REST_USE</th>\n",
       "      <th>BIN_DRUGS</th>\n",
       "      <th>BIN_MDRDSTRD</th>\n",
       "      <th>BIN_DRIMPAIR</th>\n",
       "      <th>BIN_MFACTOR</th>\n",
       "      <th>BIN_MDRMANAV</th>\n",
       "      <th>BIN_MVISOBSC</th>\n",
       "      <th>SERIOUS_FATALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_WEEK  HOUR  RUR_URB  ROUTE  RELJCT2  WRK_ZONE  LGT_COND  \\\n",
       "0      1         5     2        1      3        1         0         2   \n",
       "1      1         5    22        1      1        1         0         2   \n",
       "2      1         5     1        1      2        1         0         2   \n",
       "4      1         1     0        1      3        1         0         2   \n",
       "5      1         4     7        2      2        2         0         1   \n",
       "\n",
       "   WEATHER  DRUNK_DR       ...        BIN_WRK_ZONE  BIN_SPEEDREL  \\\n",
       "0        1         1       ...                   0             0   \n",
       "1       10         0       ...                   0             1   \n",
       "2        1         1       ...                   0             0   \n",
       "4       10         1       ...                   0             0   \n",
       "5        1         0       ...                   0             0   \n",
       "\n",
       "   BIN_REST_USE  BIN_DRUGS  BIN_MDRDSTRD  BIN_DRIMPAIR  BIN_MFACTOR  \\\n",
       "0             0          0             0             0            0   \n",
       "1             0          0             0             0            0   \n",
       "2             0          0             0             1            0   \n",
       "4             0          0             0             1            0   \n",
       "5             1          0             0             0            0   \n",
       "\n",
       "   BIN_MDRMANAV  BIN_MVISOBSC  SERIOUS_FATALS  \n",
       "0             0             0               0  \n",
       "1             0             0               0  \n",
       "2             0             0               0  \n",
       "4             0             0               0  \n",
       "5             0             1               0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter dataset to only include drivers\n",
    "traffic_clean_ml = traffic_clean.loc[traffic_clean['PER_TYP'] == 1]\n",
    "\n",
    "#Drop columns with information proving to be duplicative or that are only reference columns\n",
    "#Drop MVIOLATN--it is after the fact and most common charge is homicide--not useful\n",
    "to_drop = ['ST_CASE', 'YEAR', 'RELJCT1','WEATHER1', 'WEATHER2', 'CF1', 'CF2', 'CF3', 'FATALS', 'VEH_NO', \n",
    "           'DEATHS', 'PER_NO', 'PER_TYP', 'INJ_SEV', 'REST_MIS', 'P_SF1', 'BIN_P_SF1', \n",
    "           'MVIOLATN']\n",
    "\n",
    "traffic_clean_ml = traffic_clean_ml.drop(to_drop, axis=1)\n",
    "\n",
    "print(traffic_clean_ml.columns)\n",
    "\n",
    "traffic_clean_ml.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Preparations of the Dataset\n",
    "\n",
    "I then filtered the dataset to include information pertaining only to drivers, rather than passengers or pedestrians, by setting the variable Person Type ('PER_TYP') equal to 1, Driver of a Motor Vehicle In-Transport. I then dropped a number of variables that, upon further examination, proved to contain duplicative information, such as 'WEATHER1', 'WEATHER2', 'CF1', 'CF2' and 'CF3' (containing causation information included in other variables) in an effort to simplify the model and reduce the chances of overfitting.  I also dropped irrelevant index variables that were used to initially create the dataset from separate datasets during the data wrangling phase, such as 'ST_CASE', 'VEH_NO' and 'PER_NO'. \n",
    "\n",
    "Most of the other variables were categorical in nature, and therefore had to be converted into binary variables in order to be used by the model in Sci-Kit Learn (hereinafter, \"sklearn\").  Some of these I converted by hand where the variable could be easily summarized by two classes (Rural(1) or Urban(0) or Traffic Control Device functioning or not (VTCONT_F = 1 or 0), for example. Other variables contained details that I surmised could have been useful to the model, such as WEATHER and road surface conditions ('VSURCOND'), so I created a dictionary of keys and values based on the numerical codes and corresponding definitions for these variables found in NHTSA's Fatality Analysis Reporting System Analytical User’s Manual, August 2016.  I then looped through this dictionary, converting the numerical codes into strings of the definitions provided. The variables were then in the proper state to be converted into binary variables later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26097\n",
       "0    25883\n",
       "Name: BIN_RUR_URB, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert RUR_URB to binary rural (1) or urban (2)--unknown values split evenly between the two\n",
    "\n",
    "rur_urb = traffic_clean_ml.loc[(traffic_clean_ml['RUR_URB'] > 2), 'RUR_URB']\n",
    "\n",
    "rur_urb1 = traffic_clean_ml.loc[(traffic_clean_ml['RUR_URB'] > 2), 'RUR_URB'][0:int(np.round((len(rur_urb)/2)))].replace([6, 8, 9], 1)\n",
    "rur_urb2 = traffic_clean_ml.loc[(traffic_clean_ml['RUR_URB'] > 2), 'RUR_URB'][int(np.round((len(rur_urb)/2))):] = rur_urb[int(np.round((len(rur_urb)/2))):].replace([6, 8, 9], 2)\n",
    "\n",
    "#Create copy column to be turned into binary\n",
    "traffic_clean_ml['BIN_RUR_URB'] = traffic_clean_ml['RUR_URB']\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_RUR_URB'] > 2), 'BIN_RUR_URB'] = rur_urb2.append(rur_urb1)\n",
    "\n",
    "\n",
    "#Convert 2 (Urban) to 0 for binary purposes\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_RUR_URB'] == 2), 'BIN_RUR_URB'] = 0\n",
    "\n",
    "#traffic_clean_lr['RUR_URB'].value_counts()\n",
    "traffic_clean_ml['BIN_RUR_URB'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     32885\n",
       "2     11009\n",
       "3      3806\n",
       "8      1953\n",
       "18      777\n",
       "5       615\n",
       "19      287\n",
       "20      222\n",
       "4       197\n",
       "6       106\n",
       "7        94\n",
       "17       19\n",
       "16       10\n",
       "Name: RELJCT2, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert RELJCT2 to binary\n",
    "\n",
    "#Change 99, Unknown, and 98, Not Reported, to 1, Non-Junction\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['RELJCT2'] == 99) | (traffic_clean_ml['RELJCT2'] == 98), 'RELJCT2'] = 1\n",
    "\n",
    "traffic_clean_ml['RELJCT2'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Junction                              32885\n",
       "Intersection                              11009\n",
       "Intersection Related                       3806\n",
       "Driveway Access Related                    1953\n",
       "Through Roadway                             777\n",
       "Entrance/Exit Ramp Related                  615\n",
       "Other Location Within Interchange Area      287\n",
       "Entrance/Exit Ramp                          222\n",
       "Driveway Access                             197\n",
       "Railway Grade Crossing                      106\n",
       "Crossover Related                            94\n",
       "Acceleration/Deceleration Lane               19\n",
       "Shared-Use Path Crossing                     10\n",
       "Name: RELJCT2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary based on NHTSA manual-given values\n",
    "\n",
    "junc_dict = {\n",
    "    1: 'Non-Junction',\n",
    "    2: 'Intersection',\n",
    "    3: 'Intersection Related',\n",
    "    4: 'Driveway Access',\n",
    "    5: 'Entrance/Exit Ramp Related',\n",
    "    6: 'Railway Grade Crossing',\n",
    "    7: 'Crossover Related',\n",
    "    8: 'Driveway Access Related',\n",
    "    16: 'Shared-Use Path Crossing',\n",
    "    17: 'Acceleration/Deceleration Lane',\n",
    "    18: 'Through Roadway',\n",
    "    19: 'Other Location Within Interchange Area',\n",
    "    20: 'Entrance/Exit Ramp'\n",
    "}\n",
    "\n",
    "#Loop through values in column and reset values matching key to value in dictionary \n",
    "#to get substantive information for variable\n",
    "\n",
    "for i in np.arange(0, len(traffic_clean_ml['RELJCT2'])):\n",
    "    for key, val in junc_dict.items():\n",
    "        if i == key:\n",
    "            traffic_clean_ml['RELJCT2'].replace(i, val, inplace=True)\n",
    "\n",
    "\n",
    "#Check values\n",
    "traffic_clean_ml['RELJCT2'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    27004\n",
       "2    13302\n",
       "3     8963\n",
       "5     1360\n",
       "4     1034\n",
       "6      317\n",
       "Name: LGT_COND, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert LGT_COND to binary--Change to descriptions--use get_dummies later\n",
    "#Remove unknown values--change to 1 Daylight\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['LGT_COND'] == 7) | (traffic_clean_ml['LGT_COND'] == 8) |  (traffic_clean_ml['LGT_COND'] == 9), 'LGT_COND'] = 1\n",
    "\n",
    "traffic_clean_ml['LGT_COND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Daylight                   27004\n",
       "Dark – Not Lighted         13302\n",
       "Dark – Lighted              8963\n",
       "Dusk                        1360\n",
       "Dawn                        1034\n",
       "Dark – Unknown Lighting      317\n",
       "Name: LGT_COND, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary based on NHTSA manual-given values\n",
    "\n",
    "light_dict = {\n",
    "    1: 'Daylight',\n",
    "    2: 'Dark – Not Lighted',\n",
    "    3: 'Dark – Lighted',\n",
    "    4: 'Dawn',\n",
    "    5: 'Dusk',\n",
    "    6: 'Dark – Unknown Lighting'\n",
    "}\n",
    "\n",
    "\n",
    "#Loop through values in column and reset values matching key to value in dictionary \n",
    "#to get substantive information for variable\n",
    "\n",
    "for i in np.arange(0, len(traffic_clean_ml['LGT_COND'])):\n",
    "    for key, val in light_dict.items():\n",
    "        if i == key:\n",
    "            traffic_clean_ml['LGT_COND'].replace(i, val, inplace=True)\n",
    "\n",
    "\n",
    "#Check values\n",
    "traffic_clean_ml['LGT_COND'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     37584\n",
       "10     8643\n",
       "2      3956\n",
       "5       674\n",
       "4       627\n",
       "3       171\n",
       "11       98\n",
       "8        83\n",
       "7        73\n",
       "12       40\n",
       "6        31\n",
       "Name: WEATHER, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert WEATHER to binary--first get descriptions, then convert using get_dummies later\n",
    "#Remove unknown values--change to 1 Clear\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['WEATHER'] == 98) | (traffic_clean_ml['WEATHER'] == 99), 'WEATHER'] = 1\n",
    "\n",
    "traffic_clean_ml['WEATHER'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clear                       37584\n",
       "Cloudy                       8643\n",
       "Rain                         3956\n",
       "Fog, Smog, Smoke              674\n",
       "Snow                          627\n",
       "Sleet, Hail                   171\n",
       "Blowing Snow                   98\n",
       "Other (Adverse Weather)        83\n",
       "Blowing Sand, Soil, Dirt       73\n",
       "Freezing Rain or Drizzle       40\n",
       "Severe Crosswinds              31\n",
       "Name: WEATHER, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary based on NHTSA manual-given values\n",
    "\n",
    "weather_dict = {\n",
    "    1: 'Clear',\n",
    "    2: 'Rain',\n",
    "    3: 'Sleet, Hail',\n",
    "    4: 'Snow',\n",
    "    5: 'Fog, Smog, Smoke',\n",
    "    6: 'Severe Crosswinds',\n",
    "    7: 'Blowing Sand, Soil, Dirt',\n",
    "    8: 'Other (Adverse Weather)',\n",
    "    10: 'Cloudy',\n",
    "    11: 'Blowing Snow',\n",
    "    12: 'Freezing Rain or Drizzle'\n",
    "}\n",
    "\n",
    "#Loop through values in column and reset values matching key to value in dictionary \n",
    "#to get substantive information for variable\n",
    "\n",
    "for i in np.arange(0, len(traffic_clean_ml['WEATHER'])):\n",
    "    for key, val in weather_dict.items():\n",
    "        if i == key:\n",
    "            traffic_clean_ml['WEATHER'].replace(i, val, inplace=True)\n",
    "\n",
    "\n",
    "#Check values\n",
    "traffic_clean_ml['WEATHER'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    51844\n",
       "1      136\n",
       "Name: BIN_HAZ_INV, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert HAZ_INV to true binary--change 1 to 0 first (1 = \"No\" here), then 2 = 1\n",
    "\n",
    "traffic_clean_ml['BIN_HAZ_INV'] = traffic_clean_ml['HAZ_INV']\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_HAZ_INV'] == 1), 'BIN_HAZ_INV'] = 0\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_HAZ_INV'] == 2), 'BIN_HAZ_INV'] = 1\n",
    "\n",
    "traffic_clean_ml['BIN_HAZ_INV'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     43981\n",
       "2      6132\n",
       "4       641\n",
       "3       589\n",
       "0       311\n",
       "10      124\n",
       "11      105\n",
       "6        89\n",
       "5         5\n",
       "7         3\n",
       "Name: VSURCOND, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert VSURCOND to binary--first get descriptions, then convert using get_dummies later\n",
    "#Remove unknown/Other values--change to 1, Dry\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['VSURCOND'] == 98) | (traffic_clean_ml['VSURCOND'] == 99) | (traffic_clean_ml['VSURCOND'] == 8), 'VSURCOND'] = 1\n",
    "\n",
    "traffic_clean_ml['VSURCOND'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dry                                       43981\n",
       "Wet                                        6132\n",
       "Ice/Frost                                   641\n",
       "Snow                                        589\n",
       "Non-Trafficway Area or Driveway Access      311\n",
       "Slush                                       124\n",
       "Mud, Dirt, Gravel                           105\n",
       "Water (Standing or Moving)                   89\n",
       "Sand                                          5\n",
       "Oil                                           3\n",
       "Name: VSURCOND, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary based on NHTSA manual-given values\n",
    "\n",
    "surface_dict = {\n",
    "    0: 'Non-Trafficway Area or Driveway Access',\n",
    "    1: 'Dry',\n",
    "    2: 'Wet',\n",
    "    3: 'Snow',\n",
    "    4: 'Ice/Frost',\n",
    "    5: 'Sand',\n",
    "    6: 'Water (Standing or Moving)',\n",
    "    7: 'Oil',\n",
    "    10: 'Slush',\n",
    "    11: 'Mud, Dirt, Gravel'\n",
    "}\n",
    "\n",
    "#Loop through values in column and reset values matching key to value in dictionary \n",
    "#to get substantive information for variable\n",
    "\n",
    "for i in np.arange(0, len(traffic_clean_ml['VSURCOND'])):\n",
    "    for key, val in surface_dict.items():\n",
    "        if i == key:\n",
    "            traffic_clean_ml['VSURCOND'].replace(i, val, inplace=True)\n",
    "\n",
    "\n",
    "#Check values\n",
    "traffic_clean_ml['VSURCOND'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41699\n",
       "1    10281\n",
       "Name: BIN_VTCONT_F, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to binary--change unknowns 8 and 9 to zero\n",
    "\n",
    "traffic_clean_ml['BIN_VTCONT_F'] = traffic_clean_ml['VTCONT_F']\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_VTCONT_F'] == 8) | (traffic_clean_ml['BIN_VTCONT_F'] == 9), 'BIN_VTCONT_F'] = 0\n",
    "\n",
    "#Convert 1 (not functioning) and 2 (not functioning properly) to zero (no controls) \n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_VTCONT_F'] < 3), 'BIN_VTCONT_F'] = 0\n",
    "\n",
    "#Then convert the rest (3, functioning) to 1\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_VTCONT_F'] == 3), 'BIN_VTCONT_F'] = 1\n",
    "\n",
    "traffic_clean_ml['BIN_VTCONT_F'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39450\n",
       "2     5603\n",
       "6     2962\n",
       "5     2163\n",
       "3     1283\n",
       "0      311\n",
       "4      208\n",
       "Name: VPROFILE, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert VPROFILE to binary--first get descriptions, then convert using get_dummies later\n",
    "#Remove unknown/Other values--change to 1, Level\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['VPROFILE'] == 8) | (traffic_clean_ml['VPROFILE'] == 9), 'VPROFILE'] = 1\n",
    "\n",
    "traffic_clean_ml['VPROFILE'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Level                                39450\n",
       "Grade, Unknown Slope                  5603\n",
       "Downhill                              2962\n",
       "Uphill                                2163\n",
       "Hillcrest                             1283\n",
       "Non-Trafficway or Driveway Access      311\n",
       "Sag (Bottom)                           208\n",
       "Name: VPROFILE, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary based on NHTSA manual-given values\n",
    "\n",
    "road_grade_dict = {\n",
    "    0: 'Non-Trafficway or Driveway Access',\n",
    "    1: 'Level',\n",
    "    2: 'Grade, Unknown Slope',\n",
    "    3: 'Hillcrest',\n",
    "    4: 'Sag (Bottom)',\n",
    "    5: 'Uphill',\n",
    "    6: 'Downhill'\n",
    "}\n",
    "\n",
    "#Loop through values in column and reset values matching key to value in dictionary \n",
    "#to get substantive information for variable\n",
    "\n",
    "for i in np.arange(0, len(traffic_clean_ml['VPROFILE'])):\n",
    "    for key, val in road_grade_dict.items():\n",
    "        if i == key:\n",
    "            traffic_clean_ml['VPROFILE'].replace(i, val, inplace=True)\n",
    "\n",
    "\n",
    "#Check values\n",
    "traffic_clean_ml['VPROFILE'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35650\n",
       "0    16330\n",
       "Name: BIN_VSPD_LIM, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert VSPD_LIM to binary--0 for City Speeds, 1 for Highway Speeds\n",
    "#Remove unknown/Other values 98, 99--change to zero\n",
    "traffic_clean_ml['BIN_VSPD_LIM'] = traffic_clean_ml['VSPD_LIM']\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_VSPD_LIM'] == 98) | (traffic_clean_ml['BIN_VSPD_LIM'] == 99), 'BIN_VSPD_LIM'] = 0\n",
    "\n",
    "#Convert speeds greater than or equal to 45 to 1--deemed highway speeds\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_VSPD_LIM'] >= 45), 'BIN_VSPD_LIM'] = 1\n",
    "\n",
    "#Convert remaining speeds less than 45 to 0--deemed city speeds\n",
    "\n",
    "traffic_clean_ml.loc[(traffic_clean_ml['BIN_VSPD_LIM'] != 1), 'BIN_VSPD_LIM'] = 0\n",
    "\n",
    "traffic_clean_ml['BIN_VSPD_LIM'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     4921\n",
       "8     4865\n",
       "10    4830\n",
       "5     4582\n",
       "9     4547\n",
       "6     4482\n",
       "12    4412\n",
       "11    4384\n",
       "4     3971\n",
       "3     3961\n",
       "1     3822\n",
       "2     3203\n",
       "Name: MONTH, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert MONTH to binary--first get descriptions, then convert using get_dummies later\n",
    "#Check for unknown/Other values--None\n",
    "\n",
    "traffic_clean_ml['MONTH'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "July         4921\n",
       "August       4865\n",
       "October      4830\n",
       "May          4582\n",
       "September    4547\n",
       "June         4482\n",
       "December     4412\n",
       "November     4384\n",
       "April        3971\n",
       "March        3961\n",
       "January      3822\n",
       "February     3203\n",
       "Name: MONTH, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary based on NHTSA manual-given values\n",
    "\n",
    "month_dict = {\n",
    "    1: 'January',\n",
    "    2: 'February',\n",
    "    3: 'March',\n",
    "    4: 'April',\n",
    "    5: 'May',\n",
    "    6: 'June',\n",
    "    7: 'July',\n",
    "    8: 'August',\n",
    "    9: 'September',\n",
    "    10: 'October',\n",
    "    11: 'November',\n",
    "    12: 'December'\n",
    "}\n",
    "\n",
    "#Loop through values in column and reset values matching key to value in dictionary \n",
    "#to get substantive information for variable\n",
    "\n",
    "for i in np.arange(0, len(traffic_clean_ml['MONTH'])):\n",
    "    for key, val in month_dict.items():\n",
    "        if i == key:\n",
    "            traffic_clean_ml['MONTH'].replace(i, val, inplace=True)\n",
    "\n",
    "\n",
    "#Check values\n",
    "traffic_clean_ml['MONTH'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    8839\n",
       "6    8040\n",
       "1    8039\n",
       "5    7175\n",
       "4    6818\n",
       "3    6537\n",
       "2    6532\n",
       "Name: DAY_WEEK, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert DAY_WEEK to binary--first get descriptions, then convert using get_dummies later\n",
    "#Check for unknown/Other values--None\n",
    "\n",
    "traffic_clean_ml['DAY_WEEK'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saturday     8839\n",
       "Friday       8040\n",
       "Sunday       8039\n",
       "Thursday     7175\n",
       "Wednesday    6818\n",
       "Tuesday      6537\n",
       "Monday       6532\n",
       "Name: DAY_WEEK, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary based on NHTSA manual-given values\n",
    "\n",
    "weekday_dict = {\n",
    "    1: 'Sunday',\n",
    "    2: 'Monday',\n",
    "    3: 'Tuesday',\n",
    "    4: 'Wednesday',\n",
    "    5: 'Thursday',\n",
    "    6: 'Friday',\n",
    "    7: 'Saturday'\n",
    "}\n",
    "\n",
    "#Loop through values in column and reset values matching key to value in dictionary \n",
    "#to get substantive information for variable\n",
    "\n",
    "for i in np.arange(0, len(traffic_clean_ml['DAY_WEEK'])):\n",
    "    for key, val in weekday_dict.items():\n",
    "        if i == key:\n",
    "            traffic_clean_ml['DAY_WEEK'].replace(i, val, inplace=True)\n",
    "\n",
    "\n",
    "#Check values\n",
    "traffic_clean_ml['DAY_WEEK'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three of the variables were purely numerical variables, Travel Speed ('TRAV_SP'), the driver's age ('AGE') and the number of drunk drivers involved in the accident ('DRUNK_DR'). Since nearly all of the other variables in the model were going to be binary categorical variables, I determined that the three numeric variables needed to be standardized in order to place them on roughly the same footing as the binaries so as not to unduly skew the data.  Accordingly, I divided each variable by twice their standard deviations.  *See also*, [here](http://andrewgelman.com/2009/07/11/when_to_standar/), providing additional justification for the aforementioned procedure.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAV_SP</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DRUNK_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.023354</td>\n",
       "      <td>1.809944</td>\n",
       "      <td>1.048516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.302451</td>\n",
       "      <td>1.304224</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488515</td>\n",
       "      <td>0.825121</td>\n",
       "      <td>1.048516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.395483</td>\n",
       "      <td>1.064673</td>\n",
       "      <td>1.048516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.279097</td>\n",
       "      <td>0.638804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRAV_SP       AGE  DRUNK_DR\n",
       "0  1.023354  1.809944  1.048516\n",
       "1  1.302451  1.304224  0.000000\n",
       "2  1.488515  0.825121  1.048516\n",
       "4  1.395483  1.064673  1.048516\n",
       "5  0.279097  0.638804  0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardize numerical variables--divide by 2 standard deviations to place on approximately \n",
    "#equal footing with remaining binary variables.\n",
    "\n",
    "num_vars = ['TRAV_SP', 'AGE', 'DRUNK_DR']\n",
    "\n",
    "for v in num_vars:\n",
    "    traffic_clean_ml[v] = traffic_clean_ml[v]/(2 * np.std(traffic_clean_ml[v]))\n",
    "\n",
    "\n",
    "#Show standardized variables\n",
    "traffic_clean_ml[num_vars].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then converted the variables with descriptions obtained from the NHTSA manual to binaries using pandas' get_dummies function, resulting in the creation of several new binary columns.  The original, non-binary columns were then dropped. At this point, the dataframe contained 77 columns and was ready for the application of machine learning algorithms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUR</th>\n",
       "      <th>RUR_URB</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>WRK_ZONE</th>\n",
       "      <th>DRUNK_DR</th>\n",
       "      <th>HAZ_INV</th>\n",
       "      <th>TRAV_SP</th>\n",
       "      <th>SPEEDREL</th>\n",
       "      <th>VSPD_LIM</th>\n",
       "      <th>VPAVETYP</th>\n",
       "      <th>...</th>\n",
       "      <th>BIN_Other (Adverse Weather)</th>\n",
       "      <th>BIN_Rain</th>\n",
       "      <th>BIN_Severe Crosswinds</th>\n",
       "      <th>BIN_Sleet, Hail</th>\n",
       "      <th>BIN_Snow</th>\n",
       "      <th>BIN_Dark – Not Lighted</th>\n",
       "      <th>BIN_Dark – Unknown Lighting</th>\n",
       "      <th>BIN_Dawn</th>\n",
       "      <th>BIN_Daylight</th>\n",
       "      <th>BIN_Dusk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.048516</td>\n",
       "      <td>1</td>\n",
       "      <td>1.023354</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.302451</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.048516</td>\n",
       "      <td>1</td>\n",
       "      <td>1.488515</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.048516</td>\n",
       "      <td>1</td>\n",
       "      <td>1.395483</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.279097</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOUR  RUR_URB  ROUTE  WRK_ZONE  DRUNK_DR  HAZ_INV   TRAV_SP  SPEEDREL  \\\n",
       "0     2        1      3         0  1.048516        1  1.023354         0   \n",
       "1    22        1      1         0  0.000000        1  1.302451         4   \n",
       "2     1        1      2         0  1.048516        1  1.488515         0   \n",
       "4     0        1      3         0  1.048516        1  1.395483         0   \n",
       "5     7        2      2         0  0.000000        1  0.279097         0   \n",
       "\n",
       "   VSPD_LIM  VPAVETYP    ...     BIN_Other (Adverse Weather)  BIN_Rain  \\\n",
       "0        55         2    ...                               0         0   \n",
       "1        70         2    ...                               0         0   \n",
       "2        55         2    ...                               0         0   \n",
       "4        55         2    ...                               0         0   \n",
       "5        65         2    ...                               0         0   \n",
       "\n",
       "   BIN_Severe Crosswinds  BIN_Sleet, Hail  BIN_Snow  BIN_Dark – Not Lighted  \\\n",
       "0                      0                0         0                       1   \n",
       "1                      0                0         0                       1   \n",
       "2                      0                0         0                       1   \n",
       "4                      0                0         0                       1   \n",
       "5                      0                0         0                       0   \n",
       "\n",
       "   BIN_Dark – Unknown Lighting  BIN_Dawn  BIN_Daylight  BIN_Dusk  \n",
       "0                            0         0             0         0  \n",
       "1                            0         0             0         0  \n",
       "2                            0         0             0         0  \n",
       "4                            0         0             0         0  \n",
       "5                            0         0             1         0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dummy variables based on substantive descriptions\n",
    "\n",
    "traffic_clean_ml = pd.get_dummies(traffic_clean_ml, prefix='BIN', columns=['MONTH', 'DAY_WEEK',\n",
    "                'RELJCT2', 'VPROFILE', 'VSURCOND', 'WEATHER', 'LGT_COND'], drop_first=True)\n",
    "    \n",
    "traffic_clean_ml.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HOUR', 'RUR_URB', 'ROUTE', 'WRK_ZONE', 'DRUNK_DR', 'HAZ_INV',\n",
       "       'TRAV_SP', 'SPEEDREL', 'VSPD_LIM', 'VPAVETYP', 'VTRAFCON', 'VTCONT_F',\n",
       "       'AGE', 'REST_USE', 'DRUGS', 'MDRDSTRD', 'DRIMPAIR', 'MFACTOR',\n",
       "       'MDRMANAV', 'MVISOBSC', 'BIN_WRK_ZONE', 'BIN_SPEEDREL', 'BIN_REST_USE',\n",
       "       'BIN_DRUGS', 'BIN_MDRDSTRD', 'BIN_DRIMPAIR', 'BIN_MFACTOR',\n",
       "       'BIN_MDRMANAV', 'BIN_MVISOBSC', 'SERIOUS_FATALS', 'BIN_RUR_URB',\n",
       "       'BIN_HAZ_INV', 'BIN_VTCONT_F', 'BIN_VSPD_LIM', 'BIN_August',\n",
       "       'BIN_December', 'BIN_February', 'BIN_January', 'BIN_July', 'BIN_June',\n",
       "       'BIN_March', 'BIN_May', 'BIN_November', 'BIN_October', 'BIN_September',\n",
       "       'BIN_Monday', 'BIN_Saturday', 'BIN_Sunday', 'BIN_Thursday',\n",
       "       'BIN_Tuesday', 'BIN_Wednesday', 'BIN_Crossover Related',\n",
       "       'BIN_Driveway Access', 'BIN_Driveway Access Related',\n",
       "       'BIN_Entrance/Exit Ramp', 'BIN_Entrance/Exit Ramp Related',\n",
       "       'BIN_Intersection', 'BIN_Intersection Related', 'BIN_Non-Junction',\n",
       "       'BIN_Other Location Within Interchange Area',\n",
       "       'BIN_Railway Grade Crossing', 'BIN_Shared-Use Path Crossing',\n",
       "       'BIN_Through Roadway', 'BIN_Grade, Unknown Slope', 'BIN_Hillcrest',\n",
       "       'BIN_Level', 'BIN_Non-Trafficway or Driveway Access',\n",
       "       'BIN_Sag (Bottom)', 'BIN_Uphill', 'BIN_Ice/Frost',\n",
       "       'BIN_Mud, Dirt, Gravel', 'BIN_Non-Trafficway Area or Driveway Access',\n",
       "       'BIN_Oil', 'BIN_Sand', 'BIN_Slush', 'BIN_Snow',\n",
       "       'BIN_Water (Standing or Moving)', 'BIN_Wet', 'BIN_Blowing Snow',\n",
       "       'BIN_Clear', 'BIN_Cloudy', 'BIN_Fog, Smog, Smoke',\n",
       "       'BIN_Freezing Rain or Drizzle', 'BIN_Other (Adverse Weather)',\n",
       "       'BIN_Rain', 'BIN_Severe Crosswinds', 'BIN_Sleet, Hail', 'BIN_Snow',\n",
       "       'BIN_Dark – Not Lighted', 'BIN_Dark – Unknown Lighting', 'BIN_Dawn',\n",
       "       'BIN_Daylight', 'BIN_Dusk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show all new columns\n",
    "traffic_clean_ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HOUR', 'DRUNK_DR', 'TRAV_SP', 'AGE', 'BIN_WRK_ZONE', 'BIN_SPEEDREL',\n",
      "       'BIN_REST_USE', 'BIN_DRUGS', 'BIN_MDRDSTRD', 'BIN_DRIMPAIR',\n",
      "       'BIN_MFACTOR', 'BIN_MDRMANAV', 'BIN_MVISOBSC', 'SERIOUS_FATALS',\n",
      "       'BIN_RUR_URB', 'BIN_HAZ_INV', 'BIN_VTCONT_F', 'BIN_VSPD_LIM',\n",
      "       'BIN_August', 'BIN_December', 'BIN_February', 'BIN_January', 'BIN_July',\n",
      "       'BIN_June', 'BIN_March', 'BIN_May', 'BIN_November', 'BIN_October',\n",
      "       'BIN_September', 'BIN_Monday', 'BIN_Saturday', 'BIN_Sunday',\n",
      "       'BIN_Thursday', 'BIN_Tuesday', 'BIN_Wednesday', 'BIN_Crossover Related',\n",
      "       'BIN_Driveway Access', 'BIN_Driveway Access Related',\n",
      "       'BIN_Entrance/Exit Ramp', 'BIN_Entrance/Exit Ramp Related',\n",
      "       'BIN_Intersection', 'BIN_Intersection Related', 'BIN_Non-Junction',\n",
      "       'BIN_Other Location Within Interchange Area',\n",
      "       'BIN_Railway Grade Crossing', 'BIN_Shared-Use Path Crossing',\n",
      "       'BIN_Through Roadway', 'BIN_Grade, Unknown Slope', 'BIN_Hillcrest',\n",
      "       'BIN_Level', 'BIN_Non-Trafficway or Driveway Access',\n",
      "       'BIN_Sag (Bottom)', 'BIN_Uphill', 'BIN_Ice/Frost',\n",
      "       'BIN_Mud, Dirt, Gravel', 'BIN_Non-Trafficway Area or Driveway Access',\n",
      "       'BIN_Oil', 'BIN_Sand', 'BIN_Slush', 'BIN_Snow',\n",
      "       'BIN_Water (Standing or Moving)', 'BIN_Wet', 'BIN_Blowing Snow',\n",
      "       'BIN_Clear', 'BIN_Cloudy', 'BIN_Fog, Smog, Smoke',\n",
      "       'BIN_Freezing Rain or Drizzle', 'BIN_Other (Adverse Weather)',\n",
      "       'BIN_Rain', 'BIN_Severe Crosswinds', 'BIN_Sleet, Hail', 'BIN_Snow',\n",
      "       'BIN_Dark – Not Lighted', 'BIN_Dark – Unknown Lighting', 'BIN_Dawn',\n",
      "       'BIN_Daylight', 'BIN_Dusk'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUR</th>\n",
       "      <th>DRUNK_DR</th>\n",
       "      <th>TRAV_SP</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BIN_WRK_ZONE</th>\n",
       "      <th>BIN_SPEEDREL</th>\n",
       "      <th>BIN_REST_USE</th>\n",
       "      <th>BIN_DRUGS</th>\n",
       "      <th>BIN_MDRDSTRD</th>\n",
       "      <th>BIN_DRIMPAIR</th>\n",
       "      <th>...</th>\n",
       "      <th>BIN_Other (Adverse Weather)</th>\n",
       "      <th>BIN_Rain</th>\n",
       "      <th>BIN_Severe Crosswinds</th>\n",
       "      <th>BIN_Sleet, Hail</th>\n",
       "      <th>BIN_Snow</th>\n",
       "      <th>BIN_Dark – Not Lighted</th>\n",
       "      <th>BIN_Dark – Unknown Lighting</th>\n",
       "      <th>BIN_Dawn</th>\n",
       "      <th>BIN_Daylight</th>\n",
       "      <th>BIN_Dusk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.048516</td>\n",
       "      <td>1.023354</td>\n",
       "      <td>1.809944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.302451</td>\n",
       "      <td>1.304224</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.048516</td>\n",
       "      <td>1.488515</td>\n",
       "      <td>0.825121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.048516</td>\n",
       "      <td>1.395483</td>\n",
       "      <td>1.064673</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279097</td>\n",
       "      <td>0.638804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOUR  DRUNK_DR   TRAV_SP       AGE  BIN_WRK_ZONE  BIN_SPEEDREL  \\\n",
       "0     2  1.048516  1.023354  1.809944             0             0   \n",
       "1    22  0.000000  1.302451  1.304224             0             1   \n",
       "2     1  1.048516  1.488515  0.825121             0             0   \n",
       "4     0  1.048516  1.395483  1.064673             0             0   \n",
       "5     7  0.000000  0.279097  0.638804             0             0   \n",
       "\n",
       "   BIN_REST_USE  BIN_DRUGS  BIN_MDRDSTRD  BIN_DRIMPAIR    ...     \\\n",
       "0             0          0             0             0    ...      \n",
       "1             0          0             0             0    ...      \n",
       "2             0          0             0             1    ...      \n",
       "4             0          0             0             1    ...      \n",
       "5             1          0             0             0    ...      \n",
       "\n",
       "   BIN_Other (Adverse Weather)  BIN_Rain  BIN_Severe Crosswinds  \\\n",
       "0                            0         0                      0   \n",
       "1                            0         0                      0   \n",
       "2                            0         0                      0   \n",
       "4                            0         0                      0   \n",
       "5                            0         0                      0   \n",
       "\n",
       "   BIN_Sleet, Hail  BIN_Snow  BIN_Dark – Not Lighted  \\\n",
       "0                0         0                       1   \n",
       "1                0         0                       1   \n",
       "2                0         0                       1   \n",
       "4                0         0                       1   \n",
       "5                0         0                       0   \n",
       "\n",
       "   BIN_Dark – Unknown Lighting  BIN_Dawn  BIN_Daylight  BIN_Dusk  \n",
       "0                            0         0             0         0  \n",
       "1                            0         0             0         0  \n",
       "2                            0         0             0         0  \n",
       "4                            0         0             0         0  \n",
       "5                            0         0             1         0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop additional columns that were converted to binary or containing duplicate information\n",
    "\n",
    "to_drop2 = ['RUR_URB', 'ROUTE', 'WRK_ZONE', 'HAZ_INV', 'SPEEDREL', 'VSPD_LIM', \n",
    "           'VPAVETYP', 'VTRAFCON', 'VTCONT_F', 'REST_USE', 'DRUGS', 'MDRDSTRD', 'DRIMPAIR', 'MFACTOR',\n",
    "           'MDRMANAV', 'MVISOBSC']\n",
    "\n",
    "traffic_clean_ml = traffic_clean_ml.drop(to_drop2, axis=1)\n",
    "\n",
    "#Show final list of columns\n",
    "print(traffic_clean_ml.columns)\n",
    "\n",
    "#Convert to csv for quick future access\n",
    "traffic_clean_ml.to_csv('traffic_clean_ml.csv')\n",
    "\n",
    "traffic_clean_ml.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "After preparing the dataset, called \"traffic_clean_ml\", I first split the dataset into an input dataframe and a target series, dropping the target variable 'SERIOUS_FATALS' from the prepared dataset to create an input dataframe X and created a second single column Series y consisting only of the target variable.  \n",
    "\n",
    "I next used sklearn's train_test_split function to split both X and y into train and test variables X_train, X_test, y_train and y_test such that 80% of the total dataset would be used for training the model, while 20% was withheld as unseen data for application of the model after training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load processed dataframe from csv\n",
    "traffic_clean_ml = pd.read_csv('traffic_clean_ml.csv')\n",
    "\n",
    "#Drop extraneous column of index numbers\n",
    "traffic_clean_ml = traffic_clean_ml.drop(traffic_clean_ml.iloc[:, 0].name, axis=1)\n",
    "\n",
    "#Separate dataset into feature and target data\n",
    "X = traffic_clean_ml.drop(['SERIOUS_FATALS'], axis=1)\n",
    "y = traffic_clean_ml['SERIOUS_FATALS']\n",
    "\n",
    "#Split data into train and test sets with test size at 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the ratio of 0's to 1's in the target variable is more than 10:1.  Prediction would be very difficult for most models under these circumstances.  Therefore I utilized oversampling in order to balance out the dataset, specifically, the RandomOverSampler function from the imblearn package.  The results are shown below, first showing the original imbalanced count of the target variable's classes followed by the counts of the rebalanced data after oversampling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 37932, 1: 3652})\n",
      "Resampled dataset shape Counter({0: 37932, 1: 37932})\n"
     ]
    }
   ],
   "source": [
    "#Imbalanced data (1's vs. 0's in SERIOUS_FATALS) requires oversampling to compensate\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from collections import Counter\n",
    "\n",
    "ros_train = RandomOverSampler(random_state=42)\n",
    "X_res_train, y_res_train = ros_train.fit_sample(X_train, y_train)\n",
    "\n",
    "ros_test = RandomOverSampler(random_state=42)\n",
    "X_res_test, y_res_test = ros_test.fit_sample(X_test, y_test)\n",
    "\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_train)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the categorical nature of the input and target variables, classification models appeared to be most appropriate here.  I assessed several classification models to determine which provided the strongest predictions:  logistic regression, an ensemble voting classifier and a k-nearest neighbors classifier.  \n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "To better prepare the dataset for logistic regression, I used a feature selection algorithm, recursive feature elimination (RFE) from sklearn, in order to narrow the data down to the most useful features.  RFE selected 18 features out of the total 76 which are shown below along with their rankings, with 1 being the strongest. The input dataframe X was then filtered for these features and the train_test_split and oversampling functions were then reapplied as before.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIN_SPEEDREL :  1\n",
      "BIN_DRIMPAIR :  2\n",
      "BIN_MVISOBSC :  1\n",
      "BIN_RUR_URB :  9\n",
      "BIN_HAZ_INV :  1\n",
      "BIN_VTCONT_F :  1\n",
      "BIN_VSPD_LIM :  1\n",
      "BIN_Intersection :  1\n",
      "BIN_Non-Junction :  1\n",
      "BIN_Other Location Within Interchange Area :  1\n",
      "BIN_Railway Grade Crossing :  1\n",
      "BIN_Shared-Use Path Crossing :  1\n",
      "BIN_Through Roadway :  4\n",
      "BIN_Uphill :  1\n",
      "BIN_Sand :  6\n",
      "BIN_Slush :  5\n",
      "BIN_Water (Standing or Moving) :  7\n",
      "BIN_Rain :  1\n",
      "Top ranking features: \n",
      " ['BIN_DRIMPAIR', 'BIN_HAZ_INV', 'BIN_Intersection', 'BIN_MVISOBSC', 'BIN_Non-Junction', 'BIN_Other Location Within Interchange Area', 'BIN_RUR_URB', 'BIN_Railway Grade Crossing', 'BIN_Rain', 'BIN_SPEEDREL', 'BIN_Sand', 'BIN_Shared-Use Path Crossing', 'BIN_Slush', 'BIN_Through Roadway', 'BIN_Uphill', 'BIN_VSPD_LIM', 'BIN_VTCONT_F', 'BIN_Water (Standing or Moving)']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Find top ranking/most influential features in logistic regression using feature selection\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(logreg)\n",
    "\n",
    "rfe.fit(X_res_train, y_res_train)\n",
    "\n",
    "rankings = zip(X.columns[rfe.support_], rfe.ranking_)\n",
    "ranks = {}\n",
    "top_ranks = {}\n",
    "\n",
    "for (i, j) in rankings:\n",
    "        ranks[i] = j  \n",
    "\n",
    "for keys, vals in ranks.items():\n",
    "    if vals <= 10:\n",
    "        top_ranks[keys] = vals\n",
    "        print(keys, \": \", top_ranks[keys])\n",
    "\n",
    "print(\"Top ranking features: \\n\", sorted(list((top_ranks.keys()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 37932, 1: 3652})\n",
      "Resampled dataset shape Counter({0: 37932, 1: 37932})\n"
     ]
    }
   ],
   "source": [
    "#Use only the recursively selected features in the dataset to avoid overfitting--split and reprocess\n",
    "#Note: top ranks proved to be ineffective resulting in worse scores for all algorithms\n",
    "X = X[list(ranks.keys())]\n",
    "\n",
    "#Split data into train and test sets with test size at 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Oversample to compensate for imbalanced data\n",
    "\n",
    "ros_train = RandomOverSampler(random_state=42)\n",
    "X_res_train, y_res_train = ros_train.fit_sample(X_train, y_train)\n",
    "\n",
    "ros_test = RandomOverSampler(random_state=42)\n",
    "X_res_test, y_res_test = ros_test.fit_sample(X_test, y_test)\n",
    "\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_train)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I next performed a grid search over the C hyperparameter using GridsearchCV using a fairly wide grid from -5 to 10 in logspace. After some time, the grid search settled on a C-value of 15264.18. However, the accuracy score of this logistic regression model on the training set was a somewhat disappointing 59.96 percent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: 15264.18\n",
      "Best score is 0.5996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Set parameter grid for C values to give  fairly wide range to choose from in c-space\n",
    "c_space = np.logspace(-5, 10)\n",
    "param_grid = {'C': c_space }\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "#logreg_cv.fit(X_train, np.ravel(y_train))\n",
    "logreg_cv.fit(X_res_train, y_res_train)\n",
    "\n",
    "bestC = logreg_cv.best_params_['C']\n",
    "\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {:.2f}\".format(bestC)) \n",
    "print(\"Best score is {:.4f}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then ran the logistic regression model over the test set and obtained an accuracy score of 59.20%, very close to the accuracy score on the training set.  Thus, although the score was not impressive, there did not appear to be any overfitting here.  The Precision for the positive class (1) was .58, while the Recall (or Sensitivity) was .67.  Therefore, in 58% of cases the model correctly identified a serious fatality out of each time it predicted a serious fatality (where Precision is defined as the True Positives divided by the sum of True Positives and False Positives, $\\frac{TP}{(TP + FP)}$, where TP is True Positive and FP is False Positive). In 67% of instances it correctly identified a serious fatality out of all possible serious fatalities in the dataset (where Recall/Sensitivity is defined as True Positives divided by the sum of True Positives and False Negatives, $\\frac{TP}{(TP + FN)}$, where TP is True Positive and FN is False Negative).  The F1 score, the harmonic mean of the Precision and the Recall ($\\frac{2PR}{(P + R)}$, where P is Precision and R is Recall), was .62.  Given that the F1 score runs from 0 to 1.0, with 1.0 indicating the strongest model, this was a better than average score, though a bit mediocre.  The confusion matrix and classification report displaying the foregoing results are printed below.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5920\n",
      "[[4883 4600]\n",
      " [3138 6345]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.51      0.56      9483\n",
      "          1       0.58      0.67      0.62      9483\n",
      "\n",
      "avg / total       0.59      0.59      0.59     18966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Instantiate new instance of Logistic Regression and apply best parameter for testing\n",
    "lr = LogisticRegression(C=bestC, random_state=42)\n",
    "lr.fit(X_res_train, y_res_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = lr.predict(X_res_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(\"Accuracy: {:.4f}\".format(lr.score(X_res_test, y_res_test)))\n",
    "print(confusion_matrix(y_res_test, y_pred))\n",
    "print(classification_report(y_res_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then plotted the ROC Curve for the model, which plots the False Positive Rate vs. the True Positive Rate and compares the curve derived to a reference line with a slope of 1, indicating results that could be obtained by pure chance(equal numbers of False Positives and True Positives).  The greater the area under the curve (AUC), the more True Positives and the stronger the model. The results for the logistic regression model are shown below, showing an area of just .59 and a curve just slightly above the reference line, thus indicating a model that performs just slighly better than chance.  I therefore resolved to experiment with other classification models in an effort to obtain better results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d7ab3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_res_test, lr.predict(X_res_test))\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = lr.predict_proba(X_res_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_res_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot([0, 1], [0, 1], 'r--')\n",
    "_ = ax.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "_ = ax.set_xlabel('False Positive Rate')\n",
    "_ = ax.set_ylabel('True Positive Rate')\n",
    "_ = ax.set_title('ROC Curve')\n",
    "_ = ax.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('plots/lr_roc_curve.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier and Model Comparison\n",
    "\n",
    "I next used an ensemble Voting Classifier model that contained a logistic regression classifer, a Random Forest classifier and a K-Nearest Neighbors classifer.  After training the ensemble on the training set, I obtained an accuracy score of approximately 98.5%.  Running a loop over each component model in addition to the Voting Classifier, I obtained the following accuracy scores for the test data to the nearest tenth of a percent:  Logistic Regression at 58.9% (not using feature reduction or hyperparameter selection here), Random Forest at 61.0%, K-Nearest Neighbors at 75.8% and the Voting Classifier at 70.7%.  \n",
    "\n",
    "I attempted to improve the results from the Random Forest and Voting Classifier and in both cases still got inferior results compared to K-Neighbors.  \n",
    "\n",
    "For Random forest, I increased the number of trees to 300.  The improvement to the accuracy score was about .5 percent.  I ran small loop from 10, the default value, to 30 similar to what I did for knn to get an optimum number of estimators, just to see if there was any improvement as the number of estimators was increased and there was virtually none, as shown in the bottom cell.  \n",
    "\n",
    "I then attempted to use 300 estimators directly in the Voting Classifier.  The accuracy score was 0.6162, only a slight improvement, and appears to be supported by the plot below.  \n",
    "\n",
    "I also attempted to adjust the weights for the Voting Classifier to get an improved score.  I adjusted the weights to [.1, .2, .7], where .1 was for the logistic regression, .2 was for the Random Forest and .7 was for KNeighbors.  The Voting Classifier had an improved score of .7575, just slightly less than the KNeighbors classifier at .7577.  \n",
    "\n",
    "I also looked at the Precision, Recall and F1 scores for both methods.  For the Random Forest (with n_estimators=300), the Precision for the positive class was a very high .98, but the Recall was only a .24.  The F1 score for the positive class was only a .38, so this simply does not appear to be a good model for this dataset.  For the Voting Classifier, the Precision for the positive class was a .85, but only a .63 for the Recall and a .72 for the F1 score.  The F1 score here on the positive class, while decent, is still .01 less than the F1 score for the positive class using KNeighbors.  Random Forest and Voting Classifier appear to be making few Type I errors, but a large number of Type II errors. \n",
    "\n",
    "Since the K-Nearest Neighbors model performed the best, I ultimately chose to use this model for the present dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "log_clf = LogisticRegression() \n",
    "rnd_clf = RandomForestClassifier(n_estimators=300, random_state=42) \n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators =[('lr', log_clf), ('rf', rnd_clf), ('knn', knn_clf)], weights = [.1, .2, .7], voting ='soft') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset X_res_train and y_res_train to previous number of features\n",
    "X = traffic_clean_ml.drop(['SERIOUS_FATALS'], axis=1)\n",
    "y = traffic_clean_ml['SERIOUS_FATALS']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into train and test sets with test size at 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Oversample train and test sets\n",
    "ros_train = RandomOverSampler(random_state=42)\n",
    "X_res_train, y_res_train = ros_train.fit_sample(X_train, y_train)\n",
    "\n",
    "ros_test = RandomOverSampler(random_state=42)\n",
    "X_res_test, y_res_test = ros_test.fit_sample(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9746\n"
     ]
    }
   ],
   "source": [
    "#Train Voting Classifier\n",
    "\n",
    "voting_clf.fit(X_res_train, y_res_train)\n",
    "\n",
    "print(\"Training score: {:.4f}\".format(voting_clf.score(X_res_train, y_res_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: \n",
      "\n",
      "LogisticRegression : 0.5893\n",
      "RandomForestClassifier : 0.6162\n",
      "KNeighborsClassifier : 0.7577\n",
      "VotingClassifier : 0.7575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Testing score: \\n\")\n",
    "\n",
    "for clf in (log_clf, rnd_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_res_train, y_res_train)\n",
    "    y_pred = clf.predict(X_res_test)\n",
    "    print(clf.__class__.__name__, \": {:.4f}\".format(accuracy_score(y_res_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6162\n",
      "[[9446   37]\n",
      " [7242 2241]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      1.00      0.72      9483\n",
      "          1       0.98      0.24      0.38      9483\n",
      "\n",
      "avg / total       0.77      0.62      0.55     18966\n",
      "\n",
      "Accuracy score: 0.7575\n",
      "[[8402 1081]\n",
      " [3519 5964]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.89      0.79      9483\n",
      "          1       0.85      0.63      0.72      9483\n",
      "\n",
      "avg / total       0.78      0.76      0.75     18966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred1 = rnd_clf.predict(X_res_test)\n",
    "y_pred2 = voting_clf.predict(X_res_test)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_res_test, y_pred1)))\n",
    "print(confusion_matrix(y_res_test, y_pred1))\n",
    "print(classification_report(y_res_test, y_pred1))\n",
    "\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_res_test, y_pred2)))\n",
    "print(confusion_matrix(y_res_test, y_pred2))\n",
    "print(classification_report(y_res_test, y_pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset X to original values and re-process\n",
    "#Reset X_res_train and y_res_train to previous number of features\n",
    "X = traffic_clean_ml.drop(['SERIOUS_FATALS'], axis=1)\n",
    "y = traffic_clean_ml['SERIOUS_FATALS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into train and test sets with test size at 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Oversample train and test sets\n",
    "ros_train = RandomOverSampler(random_state=42)\n",
    "X_res_train, y_res_train = ros_train.fit_sample(X_train, y_train)\n",
    "\n",
    "ros_test = RandomOverSampler(random_state=42)\n",
    "X_res_test, y_res_test = ros_test.fit_sample(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier\n",
    "\n",
    "In order to obtain the optimal k to use for the K-Nearest Neighbors classifier, I looped over several possible k-values from 1 through 8 and plotted the accuracy scores for both the training set and test set in a single plot.  This plot may be viewed in the bottom cell.  (Please note that it takes a substantial amount of time to run, i.e., approximately 20 minutes, and for this reason has been set off from the other cells in this notebook.)  \n",
    "\n",
    "Although k=3 and k=4 gave the highest accuracy scores, there was still a substantial amount of overfitting here.  K-Neighbors overfits more at k=4 by 21.7 percentage points vs. k=7 with 17.4 percentage points overfitting.  The drop in test accuracy is a little under 2 percent going from k=4 (75.8%) to k=7 at 74.2%, so the small drop in accuracy of 1.6% appears to be  worth the 4.3% drop in overfitting. I also attempted to use a weighting function for the nearest neighbors such that weights would be inversely proportional to distance using the weights='distance' parameter.  However, this also resulted in overfitting, and the improvements it provided were again minimal, as illustrated further in the second to last plot below. Accordingly, I ultimately adopted k=7 as the k-value for this model with the weights equal to 1. \n",
    "\n",
    "At k=7, the training accuracy score for the K-Nearest Neighbors classifier was 91.6%, while the testing accuracy score was, as stated, 74.2%. The Precision for the positive class (1) was .76, while the Recall (or Sensitivity) was .71.  Therefore, in 76% of cases the model correctly identified a serious fatality out of each time it predicted a serious fatality. In 71% of instances it correctly identified a serious fatality out of all possible serious fatalities in the dataset.  Finally, the F1 score for the positive class was .73. All of these scores thus indicated a substantial improvement over the previous logistic regression model. The confusion matrix and classification report displaying the foregoing results are printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "knn_clf.fit(X_res_train, y_res_train)\n",
    "\n",
    "print(\"Training score: {:.4f}\".format(knn_clf.score(X_res_train, y_res_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7420\n",
      "[[7336 2147]\n",
      " [2746 6737]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75      9483\n",
      "          1       0.76      0.71      0.73      9483\n",
      "\n",
      "avg / total       0.74      0.74      0.74     18966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = knn_clf.predict(X_res_test)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_res_test, y_pred)))\n",
    "print(confusion_matrix(y_res_test, y_pred))\n",
    "print(classification_report(y_res_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then plotted the ROC Curve for the present model. The results for the K-Nearest Neighbors model are shown below, showing an area under the curve (AUC) of .74 and a curve that is substantially above the 45 degree reference line, thus indicating a model that performs much better than chance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaWUiyYFpZRSLpoUlFJKufw/oUqQqV67nQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108a2cb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "knn_roc_auc = roc_auc_score(y_res_test, knn_clf.predict(X_res_test))\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = knn_clf.predict_proba(X_res_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_res_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot([0, 1], [0, 1], 'r--')\n",
    "_ = ax.plot(fpr, tpr, label='K-Nearest Neighbors (area = %0.2f)' % knn_roc_auc)\n",
    "_ = ax.set_xlabel('False Positive Rate')\n",
    "_ = ax.set_ylabel('True Positive Rate')\n",
    "_ = ax.set_title('ROC Curve')\n",
    "_ = ax.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('plots/knn_roc_curve.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusion\n",
    "\n",
    "Despite the improved scores obtained through the K-Nearest Neighbors model on the test data, there was still overfitting unlike with the logistic regression model where feature reduction algorithms were employed.  \n",
    "\n",
    "The use of PCA and other feature-reducing tools was attempted with the K-Nearest Neighbors model, but ultimately had no beneficial impact since the nature of the data was such that each feature had to be split into many sub-features first that then needed to be binarized before being able to submit the data to a machine learning algorithm. Removing subfeatures using a feature reducer resulted in some subfeatures of a given feature being lost, but not all.  This resulted in substantially reduced accuracy when using feature reducers. Nevertheless, I was able to remove some features by hand at the outset before binarizing the variables where I observed redundancy between features. \n",
    "\n",
    "Despite attempting to use an ensemble Voting Classifier method consisting of Logistic Regression, a Random Forest and K-Nearest Neighbors, it failed to outperform K-Nearest Neighbors, as did the Random Forest by itself. Perhaps the Voting Classifier was not performing better than its components because these methods all have similar strengths and weaknesses (at least with respect to the present dataset), so we don’t have a situation where the strengths of one component make up for the weaknesses in another.  Instead there was just an averaging of results, such that the Voting Classifier would never perform better than its strongest component. The issue is likely related to the dataset itself and the way that the variables had to be subdivided into binaries, thus making it too rigid. K-Neighbors likely worked better here because, as noted by the Sci-Kit Learn User Guide, \"it does not attempt to construct a general internal model, but simply stores instances of the training data\" and \"...is often successful in classification situations where the decision boundary is very irregular\", as is likely the situation here. Based on the foregoing, the K-Nearest Neighbors method appears to be superior with respect to the present dataset.  \n",
    "\n",
    "As discussed above, I was ultimately able to reduce the extent of overfitting by selecting a higher k-value at k=7, rather than at k=4, and this appeared to provide the best trade-off between reducing overfitting and maximizing accuracy.  In addition to an improved accuracy score, the model also provided improved Precision, Recall and F1 scores and a much greater area under the curve in the model's ROC plot. Therefore, this model appears to have maximized its predictive power and successfully predicted the occurrence of serious fatalities at a high rate with the given data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110fb1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##REFERENCE ONLY--ESTABLISHES OPTIMUM K--DO NOT RUN AGAIN--20 MINUTE RUNTIME\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Neighbors variable for looping over k-values and arrays for train and test accuracies\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k using KNeighborsClassifier\n",
    "for i, k in enumerate(neighbors):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn.fit(X_res_train, y_res_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_res_train, y_res_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_res_test, y_res_test)\n",
    "\n",
    "# Plot accuracies for train and test sets for all values of k\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "_ = ax.set_title('k-NN: Accuracies for Varying Numbers of Neighbors')\n",
    "_ = ax.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "_ = ax.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "_ = ax.legend()\n",
    "_ = ax.set_xlabel('Number of Neighbors')\n",
    "_ = ax.set_ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('plots/knn_k-values.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCzMzy+RkYWZmmf4/SVMDsCSMgLsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a595feb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##REFERENCE ONLY--ESTABLISHES OPTIMUM K--DO NOT RUN AGAIN--20 MINUTE RUNTIME\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Neighbors variable for looping over k-values and arrays for train and test accuracies\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k using KNeighborsClassifier\n",
    "for i, k in enumerate(neighbors):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "\n",
    "    knn.fit(X_res_train, y_res_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_res_train, y_res_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_res_test, y_res_test)\n",
    "\n",
    "# Plot accuracies for train and test sets for all values of k\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "_ = ax.set_title('k-NN: Accuracies for Varying Numbers of Neighbors')\n",
    "_ = ax.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "_ = ax.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "_ = ax.legend()\n",
    "_ = ax.set_xlabel('Number of Neighbors')\n",
    "_ = ax.set_ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('plots/knn_k-values_weights.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a533048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Estimators variable for looping over number of estimators and arrays for train and test accuracies\n",
    "estimators = np.arange(10, 30)\n",
    "train_accuracy = np.empty(len(estimators))\n",
    "test_accuracy = np.empty(len(estimators))\n",
    "\n",
    "# Loop over different values of k using RandomForestClassifer\n",
    "for i, k in enumerate(estimators):\n",
    "    \n",
    "    rnd_clf = RandomForestClassifier(n_estimators=k, random_state=42) \n",
    "    \n",
    "    rnd_clf.fit(X_res_train, y_res_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = rnd_clf.score(X_res_train, y_res_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = rnd_clf.score(X_res_test, y_res_test)\n",
    "\n",
    "# Plot accuracies for train and test sets for all values of k\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "_ = ax.set_title('Random Forest: Accuracies for Varying Numbers of Estimators')\n",
    "_ = ax.plot(estimators, test_accuracy, label = 'Testing Accuracy')\n",
    "_ = ax.plot(estimators, train_accuracy, label = 'Training Accuracy')\n",
    "_ = ax.legend()\n",
    "_ = ax.set_xlabel('Number of Estimators')\n",
    "_ = ax.set_ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('plots/RF_Estimators.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
